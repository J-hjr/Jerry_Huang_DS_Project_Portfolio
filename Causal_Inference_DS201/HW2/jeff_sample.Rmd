---
pdf_document: default
author: "yz7936 Jeff Zheng"
date: "2023-06-20"
output:
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Packages

```{r}
library(knitr)
library(readxl)
library(dplyr)
library(ggplot2)
library(magrittr)
library(tinytex)
```

#Problem 1

##Data Loading

```{r}
gay <- read.csv("gay.csv")
```

##1.1

```{r}
#no contact
nc.w1 <- subset(gay, subset = treatment=="No Contact" & study==1 & wave==1)

#same-sex marriage script by gay canvasse
ssm.gc.w1 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Gay Canvasser" & study==1 & wave==1)

#same-sex marriage script by straight canvasser
ssm.sc.w1 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Straight Canvasser" & study==1 & wave==1)

#calculate mean of outcome
mean(nc.w1$ssm)
mean(ssm.gc.w1$ssm)
mean(ssm.sc.w1$ssm)
```

Answer: The values are pretty similar, so I believe it has been given randomly.

##1.2

```{r}
#no contact
nc.w2 <- subset(gay, subset = treatment=="No Contact" & study==1 & wave==2)

#same-sex marriage script by gay canvasser
ssm.gc.w2 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Gay Canvasser" & study==1 & wave==2)

#same-sex marriage script by straight canvasser
ssm.sc.w2 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Straight Canvasser" & study==1 & wave==2)

#calculate mean of outcome
mean(nc.w2$ssm)
mean(ssm.gc.w2$ssm)
mean(ssm.sc.w2$ssm)

#ATE for both
mean(ssm.gc.w2$ssm) - mean(nc.w2$ssm)
mean(ssm.sc.w2$ssm) - mean(nc.w2$ssm)
```

Answer: Slightly bigger difference when straight canvasser than with gay canvasser - both are positive, looking at the mean it also shows as pretty randomized.

##1.3

```{r}
#Placebo

rec.gc.w2 <- subset(gay, subset = treatment=="Recycling Script by Gay Canvasser" & study==1 & wave==2)
rec.sc.w2 <- subset(gay, subset = treatment=="Recycling Script by Straight Canvasser" & study==1 & wave==2)

#ATE
# Compare recycling script with same sex marriage script (both gay canvasser)
mean(ssm.gc.w2$ssm) - mean(rec.gc.w2$ssm)   

# Compare recycling script with same sex marriage script (both straight canvasser)
mean(ssm.sc.w2$ssm) - mean(rec.sc.w2$ssm)   
```

Answer: I believe the purpose of recycling script is to test interviewer's effect. It is also presumably to control for the potential interviewer effect on the topics.

We notice bigger difference in attitude towards same sex marriage for straight canvassers than gay canvassers.

##1.4

```{r}
#Remove restriction(Override)
#no contact
nc <- subset(gay, subset = treatment=="No Contact" & study==1)
#same-sex marriage script by gay canvasse
ssm.gc <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Gay Canvasser" & study==1)
#same-sex marriage script by straight canvasser
ssm.sc <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Straight Canvasser" & study==1)

#compare wave
tapply(nc$ssm, nc$wave, mean)
tapply(ssm.gc$ssm, ssm.gc$wave, mean)
tapply(ssm.sc$ssm, ssm.sc$wave, mean)

#compare ATE
#gay vs nc
tapply(ssm.gc$ssm, ssm.gc$wave, mean) - tapply(nc$ssm, nc$wave, mean)
#straight vs nc
tapply(ssm.sc$ssm, ssm.sc$wave, mean) - tapply(nc$ssm, nc$wave, mean)
```

Answer: We notice a bigger effect of gay canvasser over time.

##1.5

```{r}
#no contact, study 2
nc.s2.w1 <- subset(gay, subset = treatment=="No Contact" & study==2 & wave==1)

#same-sex marriage script by gay canvasser, study 2
ssm.gc.s2.w1 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Gay Canvasser" & study==2 & wave==1)

#calculate mean
mean(ssm.gc.s2.w1$ssm)
mean(nc.s2.w1$ssm)
```

Answer: Same as study1, we look at the mean. We see that the means are very similar - suggesting pre-trial randomization is good.

##1.6

```{r}
#no contact, study 2
nc.s2.w2 <- subset(gay, subset = treatment=="No Contact" & study==2 & wave==2)

#same-sex marriage script by gay canvasser, study 2
ssm.gc.s2.w2 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Gay Canvasser" & study==2 & wave==2)

#calculate mean, study 2
mean(ssm.gc.s2.w2$ssm)
mean(nc.s2.w2$ssm)

#now again, study 1
mean(ssm.gc.w2$ssm)
mean(nc.w2$ssm)
```

Answer: The value are similar, the gay canvassers elicit higher responses.

##1.7

```{r}
#Remove restriction(Override)
#no contact, study 2
nc.s2 <- subset(gay, subset = treatment=="No Contact" & study==2)

#same-sex marriage script by gay canvasser, study 2
ssm.gc.s2 <- subset(gay, subset = treatment=="Same-Sex Marriage Script by Gay Canvasser" & study==2)

#ATE
tapply(ssm.gc.s2$ssm, ssm.gc.s2$wave, mean) - tapply(nc.s2$ssm, nc.s2$wave, mean)
```

Answer: We do notice really big effects, the values increasing over time.

#Problem 2

##Data Loading

```{r}
load('fraud.rdata')
```

##2.1

```{r}
#calculate United Russia's vote share
  russia2011$vote_share <- russia2011$votes / russia2011$turnout

# Group by vote_share and count the frequency
vote_share_freq <- russia2011 %>%
    group_by(vote_share) %>%
    summarise(freq = n()) %>%
    arrange(desc(freq))

# Print the top 10 most frequently occurring fractions
top_10_fractions <- head(vote_share_freq, 10)
print(top_10_fractions)

hist(russia2011$vote_share, breaks = length(unique(russia2011$vote_share)), main = "Distribution of Vote Shares", xlab = "Vote Share", col = "lightblue", border = "black")


hist(russia2011$vote_share, breaks = length(unique(russia2011$vote_share)), main = "Vote share distribution", xlab = "Vote share", xlim = c(0.5, 0.67),col = "lightblue", border = "black")

```

Answer:

We can see that the histogram does shows spikes around 1/2, 2/3 values compared to other similar values such as 51/100, as 1.0 shows the most significant unique counts.

##2.2

```{r}
set.seed(888)  # for reproducibility

# Initialize an empty vector to store the simulated vote shares
simulated_vote_shares <- numeric()

# Run the Monte Carlo simulation
for (i in 1:1000) {
  
  # Simulate the turnout
  simulated_turnout <- rbinom(n = nrow(russia2011), size = russia2011$N, prob = russia2011$turnout / russia2011$N)
  
  # Simulate the vote share
  simulated_vote_share <- rbinom(n = nrow(russia2011), size = simulated_turnout, prob = russia2011$votes / russia2011$turnout) / simulated_turnout
  
  # Append the simulated vote shares to the vector
  simulated_vote_shares <- c(simulated_vote_shares, simulated_vote_share)
}

# Create a table of the simulated vote shares and convert it to a data frame
simulated_vote_share_freq_df <- as.data.frame(table(simulated_vote_shares))

# Rename the columns
names(simulated_vote_share_freq_df) <- c("Vote Share", "Frequency")

# Sort the data frame by frequency
simulated_vote_share_freq_df_sorted <- arrange(simulated_vote_share_freq_df, desc(Frequency))

# Print the sorted data frame
print(head(simulated_vote_share_freq_df_sorted,10))

# Create the histogram
hist(simulated_vote_shares, breaks = length(unique(simulated_vote_shares)), main = "Distribution of Simulated Vote Shares", xlab = "Vote Share")

```

Answerï¼š As we can see, the histogram shows a similar result as before(however, the hist() might be not as correct since it reaches the limit of the hist()'s length, there might be very similar values that are being shown together. e.g/ 0.5001,0.51,0.49999 in the same column as 0.5), the majority of the result has been around 1/2, 1/3, 2/3 and such.

##2.3

```{r}
# Create a subset of the data containing only the four most frequently occurring fractions
top_fractions <- c(1/2, 1/3, 3/5, 2/3)
actual_vote_share_subset <- russia2011$vote_share[russia2011$vote_share %in% top_fractions]
simulated_vote_share_subset <- simulated_vote_shares[simulated_vote_shares %in% top_fractions]

# Create histograms for the actual vote share subset
hist(actual_vote_share_subset, main = "Distribution of Actual Vote Shares for Top Fractions", xlab = "Vote Share", breaks = length(unique(actual_vote_share_subset)))

# Create histograms for the simulated vote share subset
hist(simulated_vote_share_subset, main = "Distribution of Simulated Vote Shares for Top Fractions", xlab = "Vote Share", breaks = length(unique(simulated_vote_share_subset)))

```

Answer: As we can see the vote share for both actual and simulated seems very similar, with the distribution of the two graphs(0.5 the most, then 0.3333, 0.6 and 0.6667 about the same).

#Problem 3

##Data Loading

```{r}
gotv <-read_excel("gotv_individual.xlsx")
```

##3.a

```{r}
#a
gotv$sex <- ifelse(gotv$sex == "female", 1.0, 0.0)

#b
gotv$age <- (2006 - gotv$yob)

#c
grouped_data <- gotv %>%
  group_by(hh_id) %>%
  summarize(
    treatment = first(treatment),
    hh_size = first(hh_size),
    sex = mean(sex, na.rm = TRUE),
    p2000 = mean(p2000, na.rm = TRUE),
    p2002 = mean(p2002, na.rm = TRUE),
    g2002 = mean(g2002, na.rm = TRUE),
    p2004 = mean(p2004, na.rm = TRUE),
    g2000 = mean(g2000, na.rm = TRUE),
    g2002 = mean(g2002, na.rm = TRUE),
    g2004 = mean(g2004, na.rm = TRUE),
    p2004_mean = mean(p2004_mean, na.rm = TRUE),
    g2004_mean = mean(g2004_mean, na.rm = TRUE),
    voted = mean(voted, na.rm = TRUE),
    age = mean(age, na.rm = TRUE)
  )
```

Answer: Part a,b,c has been answered using coding above.

Note that for treatment and hh_size has been used first occurrence as the data set has been given based on household rather than individual.

For part d, I believe this is because the household can influence each others result which is the why the reason the researchers wanted to analyze based on households. It is similar to the example given in class in lecture 2 about similar topics on voting. As consider if a household has been given mail, the person that read the mail the first time can then discuss with other members in the household, if the person is the elder(e.g. moms or dad), this can significantly influence the result of the individual.

##3.b

```{r}
mean_values <- grouped_data %>%
  group_by(treatment) %>%
  summarize(
    p2000 = mean(p2000, na.rm = TRUE),
    g2000 = mean(g2000, na.rm = TRUE),
    p2002 = mean(p2002, na.rm = TRUE),
    g2002 = mean(g2002, na.rm = TRUE),
    p2004 = mean(p2004, na.rm = TRUE),
    hh_size = mean(hh_size, na.rm = TRUE),
    sex = mean(sex, na.rm = TRUE),
    age = mean(age, na.rm = TRUE)
  )

print(mean_values)
```

Answer: The means of all the variables of interest (p2000, g2000, p2002, g2002, p2004, hh_size, sex, and age) are very similar across all treatment groups (Civic Duty, Control, Hawthorne, Neighbors, and Self).

This similarity of means is a good indication that the treatment assignment is randomized at the household level.In other words, the assignment of households to different treatment groups does not seem to be related to the characteristics of households, which suggests that the potential outcomes are independent of the treatment assignment given the observed variables (conditional independence assumption).

The similarity of means also suggests that "ignorability" of treatment assignment likely holds true in the experimental setup. The ignorability assumption means that the assignment to a treatment does not depend on the outcome that would have been observed under a different treatment. In this context, it suggests that the likelihood of a household being assigned to a particular treatment is not affected by the values of the variables are measured (p2000, g2000, p2002, g2002, p2004, hh_size, sex, and age).

##3.c

```{r}
ate_values <- grouped_data %>%
  group_by(treatment) %>%
  summarize(
    voted_mean = mean(voted, na.rm = TRUE)
  ) %>%
  mutate(
    ate = voted_mean - voted_mean[treatment == "Control"]
  )

print(ate_values)
```

Answer: Note that the Control ate is 0, as we are doing calculations on that, it is only being shown here so it contains everything. Two of the three assumptions:

1.SUTVA (Stable Unit Treatment Value Assumption)- This assumption has two components. First, it assumes that the outcome of a given individual depends only on his/her own treatment status, not on the treatment status of others (no interference). Second, it assumes that there is a single version of each treatment level, i.e., the treatment effect does not vary depending on how or by whom it is administered.

2.Ignorability - This assumes that the assignment of treatment is independent of the potential outcomes. In other words, receiving treatment does not depend on the potential outcomes that would have been observed under different treatment conditions. This is generally achieved through random assignment of treatment, as it should be in a well-conducted randomized controlled trial (RCT).

The others that it also suffice should be randomization and unbiasedness.

##3.d

```{r}
# Calculate the ATE
neighbors_mean <- mean(grouped_data$voted[grouped_data$treatment =="Neighbors"], na.rm = TRUE)
control_mean <- mean(grouped_data$voted[grouped_data$treatment == "Control"], na.rm = TRUE)
tau_hat <- neighbors_mean - control_mean

# Calculate the variance of ATE
neighbors_var <- var(grouped_data$voted[grouped_data$treatment =="Neighbors"], na.rm = TRUE)
control_var <- var(grouped_data$voted[grouped_data$treatment == "Control"], na.rm = TRUE)

n_neighbors <- sum(grouped_data$treatment == "Neighbors")
n_control <- sum(grouped_data$treatment == "Control")

var_tau_hat <- neighbors_var / n_neighbors + control_var / n_control


# Calculate the Z-statistic
z_stat <- sqrt(n_neighbors + n_control) * (tau_hat - 0) / sqrt(var_tau_hat)

# Calculate the p-value (two-sided test)
p_value <- 2 * pnorm(abs(z_stat), lower.tail = FALSE)

#Calculate the CI at 95%
ci_95 <- c(tau_hat - qnorm(.975)*sqrt(var_tau_hat) , tau_hat + qnorm(.975)*sqrt(var_tau_hat))
print(paste("CI at 95%: ", ci_95))

# Print the Z-statistic
print(paste("Z-statistic: ", z_stat))

# Print the p-value
print(paste("p-value: ", p_value))
```

##3.e

```{r}
# Define the number of iterations
N <- 1000

# Create an empty vector to store the simulated Zn values
simulated_Zn <- vector(length = N)

# Get the observed outcome values for the 'Neighbors' and 'Control' groups
observed_outcome <- grouped_data$voted[grouped_data$treatment %in% c("Neighbors", "Control")]

for (i in 1:N) {
  
  # Randomly shuffle the outcome values to simulate the null hypothesis
  shuffled_outcome <- sample(observed_outcome)
  
  # Assign the shuffled outcome values back to the 'Neighbors' and 'Control' groups
  grouped_data$simulated_outcome <- NA
  grouped_data$simulated_outcome[grouped_data$treatment %in% c("Neighbors", "Control")] <- shuffled_outcome
  
  # Compute the simulated tau_hat and var_tau_hat
  simulated_tau_hat <- mean(grouped_data$simulated_outcome[grouped_data$treatment == "Neighbors"], na.rm = TRUE) -
                       mean(grouped_data$simulated_outcome[grouped_data$treatment == "Control"], na.rm = TRUE)
  simulated_var_tau_hat <- var(grouped_data$simulated_outcome[grouped_data$treatment == "Neighbors"], na.rm = TRUE) / n_neighbors +
                           var(grouped_data$simulated_outcome[grouped_data$treatment == "Control"], na.rm = TRUE) / n_control
  
  # Compute the simulated Zn and store it in the vector
  simulated_Zn[i] <- sqrt(n_neighbors + n_control) * simulated_tau_hat / sqrt(simulated_var_tau_hat)
}

# Plot the histogram of the simulated Zn values
hist(simulated_Zn, col = "lightblue", main = "Histogram of Simulated Zn", xlab = "Zn", xlim = c(0, 8800))


# Add a vertical line for the observed Zn
abline(v = z_stat, col = "red", lwd = 5)

# Compute the two-sided p-value for the test
p_value_ri <- (mean(abs(simulated_Zn) >= abs(z_stat)))

# Print the p-value
print(paste("Two-sided p-value for the test: ", p_value_ri))

```

##3.f 
Answer: The p-values obtained from both tests (the Z-test in part d and the randomization test in part e) are essentially zero, they are the same and neither is smaller. This result implies that, under the null hypothesis of no difference between groups, the probability of getting a test statistic as extreme or more extreme than what I observed is virtually zero. This suggests strong evidence against the null hypothesis.


